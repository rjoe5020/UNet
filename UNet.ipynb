{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image segmentation (with U-Nets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net Architecture\n",
    "![architecture](.\\architecture.png \"UNet architecture\")\n",
    "\n",
    "### Contracting Path\n",
    "It consits of 4 blocks and every block has the same architecture (typical architecture of a concolutional network)\n",
    "1. Two 3x3 unpadded convolutions each followed by a rectified linear unit\n",
    "    - because its is unpadded we loss with every convolution 2 pixels in each dimension\n",
    "2. 2x2 max pooling operations with stride 2\n",
    "    - with this setting the image get downsampled by a factor of 2\n",
    "\n",
    "They start with 64 feature channels (filters) at the first block and with each block they double the number of feature channels\n",
    "\n",
    "The output of the last block will be sended through two convoltuion layers (3x3) each followed by a ReLU, because of the doubling of the feature channels the resulting feature map for each layer is 1024 dimensional.\n",
    "\n",
    "### Expansive Path\n",
    "Its symetric to the contracting path, so again 4 blocks. However the architecture changes slightly\n",
    "1. Upsampling by a 2x2 up-convolution (that halves the number of feature channels)\n",
    "2. Copy a cropped version of the feature map from the corresponding feature map of the contracting path and concatenate with the upsampled feature map\n",
    "    - The cropping is necessary due to the loss of border pixels in every convolution\n",
    "3. Two 3x3 unpadded convolutions each followed by a rectified linear unit\n",
    "\n",
    "At the final layer a 1x1 convolution is used to map each 64-component feature vector to the desired number of classes (in our case 2 classes). \n",
    "\n",
    "In total the network has 23 convolutional layers. (2\\*4 (Contracting Path) + 2 (last layer) + 3\\*4 (Expansive Path) + 1 (final layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because 18 of the 23 convolutional layers uses the same setting, we defined a own function for this\n",
    "def conv3x3(_input, output):\n",
    "    return nn.Conv2d(_input, output, 3, padding=0)\n",
    "\n",
    "# define block of contracting path\n",
    "class ContractingBlock(nn.Module):\n",
    "    def __init__(self,in_channels,channels):\n",
    "        super(ContractingBlock, self).__init__()\n",
    "        # for the first conv layer the number of input channels are the number of channels form the previous block and they will be doubled (first block starts with 64) \n",
    "        self.conv1 = conv3x3(in_channels,channels)\n",
    "        self.conv2 = conv3x3(channels,channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample_block = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.downsample_block(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# define block of expansive path\n",
    "class ExpansiveBlock(nn.Module):\n",
    "    def __init__(self,in_channels,channels,size,scale_factor,mode):\n",
    "        super(ExpansiveBlock, self).__init__()\n",
    "        self.interp = F.interpolate\n",
    "        self.size = size\n",
    "        self.scale_factor = scale_factor\n",
    "        self.mode = mode\n",
    "        self.convup = nn.Con2d()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.interp(x,size=self.size, scale_factor=self.scale_factor, mode=self.mode, align_corners=False)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self,num_classes=2):\n",
    "        super(Net, self).__init__()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
